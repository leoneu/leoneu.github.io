 <!--
Design by Bryant Smith
http://www.bryantsmith.com
http://www.aszx.net
email: template [-at-] bryantsmith [-dot-] com
Released under Creative Commons Attribution 2.5 Generic.  In other words, do with it what you please; but please leave the link if you'd be so kind :)

Name       : HD Monochrome
Description: One column, with top naviation.  All divs, validations: XHTML Strict 1.0 & CSS
Version    : 1.0
Released   : 20081009
-->


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" />
<title>Leo Neumeyer</title>
</head>

<body>
    <div id="page">
        <div class="topNaviagationLink"><a href="index.html">Home</a></div>
        <div class="topNaviagationLink"><a href="publications.html">Publications</a></div>
        <div class="topNaviagationLink"><a href="patents.html">Patents</a></div>
	</div>
    <div id="mainPicture">
    	<div class="picture">
        	<div id="headerTitle">4Lunas</div>
            <div id="headerSubtext">Leo Neumeyer</div>
        </div>
    </div>
        <div class="contentBox">
    	<div class="innerBox">
        	

<h1>Conducting Asynchronous Interviews over a Network</h1>

<div class="contentText">
          

<p><i>United States Patent Application  	20020040317, April 4, 2002</i></p><br />


<p>A method and apparatus are described for asynchronously conducting interviews though a user interface executing on a client. The user interface prompts an interviewee for at least one audio response, which is digitally recorded. User interfaces are generated by a client according to code defining the user interfaces downloaded from a server via, for example, the Internet. The server may be remote from the client, thereby allowing interviewees to interact with the user interfaces on their own computers. The user interface queries an interviewee and the interviewee responds, either by entering text or digitally recording a response using controls supplied by the user interface. The responses are down loaded via, for example, the Internet to a server. Evaluators may review an interviewee's response through the use of user interfaces. A user (e.g. interviewer) may specify the format of asynchronous interviews, by providing user input that specifies queries to ask, the manner of asking the queries, and the manner in which an interviewee may respond. Based on the user input, data defining the format of an asynchronous interview is generated and may be stored, for example, on a server.
</p><br />

<p>Inventors: Neumeyer, Leonardo; (Palo Alto, CA) ; Rtischev, Dimitry; (Los Altos, CA) ; Doval, Diego; (Mountain View, CA) ; Gargiulo, Juan; (Palo Alto, CA) ; Parker, Dylan; (Palo Alto, CA)</p>

</div>

<h1>Centralized Processing of Digital Speech Data Originated at the Network Clients of a set of Servers</h1>

<div class="contentText">
          
<p><a href="pub/6760697_Centralized_processing_of_digita.pdf">United States Patent 6,760,697, July 6, 2004</a></p><br />

<p>Described herein is a system that enables service provider's to integrate speech functionality into their applications. A service provider maintains a set of application servers. To provide a particular speech service to a client of the application server, the application server causes the client to request the speech service from another set of servers. This set of servers is responsible for providing this speech service as well as others. Such speech services include recording digital speech data at the client, and storing the recordings. Later, the application servers may retrieve the recordings, and even more, retrieve data derived from the recordings, such as data generated through speech recognition processes.</p><br />

<p>Inventors: Neumeyer; Leonardo (Palo Alto, CA); Rtischev; Dimitry (Menlo Park, CA); Doval; Diego (Mountain View, CA); Gargiulo; Juan (Mountain View, CA)</p><br />

</div>

<h1>Method and Apparatus for Language Training</h1>

<div class="contentText">
          
<p><a href="pub/6302695_Method_and_apparatus_for_languag.pdf">United States Patent 6,302,695, October 16, 2001</a></p><br />

<p>A method for language fluency training on a computer system having an audio output device includes invoking a web browser program, receiving a pre-recorded file including a message in a spoken language from a conversation partner, playing the message to a user seeking fluency training in the spoken language from within the web browser program on the audio output device, asynchronously with playing the message, recording a user file including a message in the spoken language from the user in response to the message from within the web browser program, outputting the user file to the conversation partner and to a language instructor, receiving an instruction file including an instruction message in the spoken language from the language instructor in response to the user message and playing the instruction message to the user from within the web browser program on the audio output device.</p><br />

<p>Inventors: Rtischev; Dimitry (Menlo Park, CA); Hubbard; Philip L. (Stanford, CA); Neumeyer; Leonardo (Palo Alto, CA); Shibatani; Kaori (San Francisco, CA)</p><br />

</div>

<h1>Method and Apparatus for Automatic Recognition using Features Encoded with Product-Space Vector Quantization</h1>

<div class="contentText">
          
<p><a href="pub/6256607_Method_and_apparatus_for_automat.pdf">United States Patent 6,256,607, July 3, 2001</a></p><br />

<p>An automatic recognition system and method divides observation vectors into subvectors and determines a quantization index for the subvectors. Subvector indices can then be transmitted or otherwise stored and used to perform recognition. In a further embodiment, recognition probabilities are determined for subvectors separately and these probabilities are combined to generate probabilities for the observed vectors. An automatic system for assigning bits to subvector indices can be used to improve recognition.</p><br />

<p>Inventors: Digalakis; Vassilios (Hania, GR); Neumeyer; Leonardo (Palo Alto, CA); Tsakalidis; Stavros (Makrohori Verias, GR); Perakakis; Manolis (Ierapetra, GR)</p>

</div>

<h1>Method and System for Automatic Text-Independent Grading of Pronunciation for Language Instruction</h1>

<div class="contentText">
          
<p><a href="pub/6226611_Method_and_system_for_automatic.pdf">United States Patent 6,226,611, May 1, 2001</a></p><br />

<p>Pronunciation quality is automatically evaluated for an utterance of speech based on one or more pronunciation scores. One type of pronunciation score is based on duration of acoustic units. Examples of acoustic units include phones and syllables. Another type of pronunciation score is based on a posterior probability that a piece of input speech corresponds to a certain model such as an HMM, given the piece of input speech. Speech may be segmented into phones and syllables for evaluation with respect to the models. The utterance of speech may be an arbitrary utterance made up of a sequence of words which had not been encountered before. Pronunciation scores are converted into grades as would be assigned by human graders. Pronunciation quality may be evaluated in a client-server language instruction environment.</p><br />

<p>Inventors: Neumeyer; Leonardo (Palo Alto, CA); Franco; Horacio (Atherton, CA); Weintraub; Mitchel (Fremont, CA); Price; Patti (Menlo Park, CA); Digalakis; Vassilios (Chania, GR)</p><br />

</div>

<h1>Method and apparatus for automatic text-independent grading of pronunciation for language instruction</h1>

<div class="contentText">
          
<p><a href="pub/6055498_Method_and_apparatus_for_automat.pdf">United States Patent 6,055,498, April 25, 2000</a></p><br />

<p>Pronunciation quality is automatically evaluated for an utterance of speech based on one or more pronunciation scores. One type of pronunciation score is based on duration of acoustic units. Examples of acoustic units include phones and syllables. Another type of pronunciation score is based on a posterior probability that a piece of input speech corresponds to a certain model, such as a hidden Markov model, given the piece of input speech. Speech may be segmented into phones and syllable for evaluation with respect to the models. The utterance of speech may be an arbitrary utterance made up of a sequence of words which had not been encountered before. Pronunciation scores are converted into grades as would be assigned by human graders. Pronunciation quality may be evaluated in a client-server language instruction environment.</p><br />

<p>Inventors: Neumeyer; Leonardo (Palo Alto, CA); Franco; Horacio (Atherton, CA); Weintraub; Mitchel (Fremont, CA); Price; Patti (Menlo Park, CA); Digalakis; Vassilios (Chania, GR)</p><br />

</div>

<h1>Method and Apparatus for Speech Recognition Adapted to an Individual Speaker</h1>

<div class="contentText">
          
<p><a href="pub/5864810_Method_and_apparatus_for_speech.pdf">United States Patent 5,864,810, January 26, 1999</a></p><br />

<p>A method and apparatus for automatic recognition of speech adapts to a particular speaker by using adaptation data to develop a transformation through which speaker independent models are transformed into speaker adapted models. The speaker adapted models are then used for speaker recognition and achieve better recognition accuracy than non-adapted models. In a further embodiment, the transformation-based adaptation technique is combined with a known Bayesian adaptation technique.</p><br />

<p>Inventors: Digalakis; Vassilios (Crete, GR); Neumeyer; Leonardo (Menlo Park, CA); Rtischev; Dimitry (Fremont, CA)</p><br />


                </div>

        
        
<!-- Please leave this in place after all of your content - thanks :) -->
<h4><a href="http://www.aszx.net">web development</a> by <a href="http://www.bryantsmith.com">bryant smith</a> | <a href="http://www.quackit.com">web tutorials</a> | <a href="http://www.htmlcodes.me">html codes</a> | <a href="http://www.free-templates.me">free templates</a></h4>
<!-- Please leave this in place after all of your content - thanks :) -->
    </div>
</div>
        
</body>
</html>
